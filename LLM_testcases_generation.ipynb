{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1VpOAmF_mHR",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers -U -q accelerate -U protobuf scipy utils datasets pandas matplotlib seaborn gdown sentencepiece nltk evaluate rouge_score\n",
        "!pip install -q -U bitsandbytes\n",
        "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "# !pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors\n",
        "!pip install -q -U torch\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JseE-h0VqIH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, LlamaForCausalLM\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from utils import *\n",
        "\n",
        "\n",
        "# from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "import datasets\n",
        "\n",
        "# # initialize the model\n",
        "# model_path = \"Phind/Phind-CodeLlama-34B-v2\"\n",
        "# model = LlamaForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsVRYZk310BD"
      },
      "outputs": [],
      "source": [
        "prompt = '''\n",
        "### System Prompt\n",
        "You are an intelligent programming Tester.\n",
        "\n",
        "### User Message\n",
        "Generate test cases for the given functions written in C such that every line of code will be excuted once at least to achieve coverging 100%\n",
        "Consider all possible combinations for the set of inputs\n",
        "\n",
        "Example:\n",
        "    Input sample:\n",
        "      // A function that calculates the factorial of a positive integer\n",
        "      int factorial(int n) {\n",
        "        // Check if n is valid\n",
        "        if (n < 0) {\n",
        "          return -1;\n",
        "        }\n",
        "        // Base case\n",
        "        if (n == 0 || n == 1) {\n",
        "          return 1;\n",
        "        }\n",
        "        // Recursive case\n",
        "        return n * factorial(n - 1);\n",
        "      }\n",
        "\n",
        "in the previous example the only input is intgre so the possible combinations is zero or positive integre or negative one\n",
        "so the following test cases cover all these combinations\n",
        "\n",
        "    Corresponding Output:\n",
        "      {\n",
        "        \"test_case 1\": [-1],\n",
        "        \"test_case 2\": [-5],\n",
        "        \"test_case 3\": [0],\n",
        "        \"test_case 4\": [1],\n",
        "        \"test_case 5\": [5]\n",
        "      }\n",
        "\n",
        "### Assistant\n",
        "// A function that reverses a string\n",
        "char* reverse_string(char* str) {\n",
        "  // Get the length of the string\n",
        "  int len = strlen(str);\n",
        "  // Allocate memory for the reversed string\n",
        "  char* rev = malloc(len + 1);\n",
        "  // Check if the memory allocation was successful\n",
        "  if (rev == NULL) {\n",
        "    return NULL;\n",
        "  }\n",
        "  // Copy the characters from the original string to the reversed string in reverse order\n",
        "  for (int i = 0; i < len; i++) {\n",
        "    rev[i] = str[len - i - 1];\n",
        "  }\n",
        "  // Add the null terminator to the reversed string\n",
        "  rev[len] = '\\0';\n",
        "  // Return the reversed string\n",
        "  return rev;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqFXNRKf-dr-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_one_completion(prompt: str):\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
        "\n",
        "    # Generate\n",
        "    generate_ids = model.generate(inputs.input_ids.to(\"cuda\"), max_new_tokens=384, do_sample=True, top_p=0.75, top_k=40, temperature=0.1)\n",
        "    completion = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    completion = completion.replace(prompt, \"\").split(\"\\n\\n\\n\")[0]\n",
        "\n",
        "    return completion\n",
        "test_cases = generate_one_completion(prompt)\n",
        "print(test_cases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC81LDc2VqIL",
        "outputId": "ec6bf720-c700-4c57-c32e-b845002bc415"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(model.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4opfYuOVqIP",
        "outputId": "91845dde-7a42-4a9b-d5f9-73a4fe35d872"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the tokenizer and the model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
        "model2 = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True).cuda()\n",
        "\n",
        "# Define a prompt that instructs the model to generate test cases for the factorial function\n",
        "prompt2 = \"\"\"\n",
        "Write test cases for the following function written in C:\n",
        "\n",
        "// A function that calculates the factorial of a positive integer\n",
        "int factorial(int n) {\n",
        "  // Check if n is valid\n",
        "  if (n < 0) {\n",
        "    return -1;\n",
        "  }\n",
        "  // Base case\n",
        "  if (n == 0 || n == 1) {\n",
        "    return 1;\n",
        "  }\n",
        "  // Recursive case\n",
        "  return n * factorial(n - 1);\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-0m85xaVqIQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True).cuda()\n",
        "# messages = [\n",
        "#     { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
        "# ]\n",
        "# inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
        "# # 32021 is the id of <|EOT|> token\n",
        "# outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=32021)\n",
        "# print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-Ln57WkVqIR"
      },
      "outputs": [],
      "source": [
        "# Use the tokenizer to encode the prompt\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
        "\n",
        "# Use the model to generate text\n",
        "outputs = model2.generate(inputs.input_ids.to(\"cuda\"), max_new_tokens=384, do_sample=True, top_p=0.75, top_k=40, temperature=0.1)\n",
        "\n",
        "# Use the tokenizer to decode the text\n",
        "text = tokenizer2.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "# Print the generated text\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5tIy8G8VqIS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# hn7ot el output bta3 el model\n",
        "json_string = '''\n",
        "{\n",
        "  \"test_case 1\": [\"Hello\"],\n",
        "  \"test_case 2\": [\"\"],\n",
        "  \"test_case 3\": [\"  Hello World  \"],\n",
        "  \"test_case 4\": [\"!@#$%^&*()\"],\n",
        "  \"test_case 5\": [\"12345\"]\n",
        "}\n",
        "'''\n",
        "data = json.loads(json_string)\n",
        "\n",
        "with open('output_parsing.txt', 'w') as txt_file:\n",
        "    for key, values in data.items():\n",
        "        txt_file.write(' '.join(map(str, values)) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5psomWKpVqIT"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import platform\n",
        "\n",
        "file_name = 'reverse_string.cpp'\n",
        "input_file_name = 'output_parsing.txt'\n",
        "\n",
        "# Compilation command\n",
        "compilation_command = f\"g++ -o {file_name.split('.')[0]} -fprofile-arcs -ftest-coverage {file_name}\"\n",
        "\n",
        "# Executable name\n",
        "executable_name = \"./\" +file_name.split('.')[0]\n",
        "\n",
        "# Executing command\n",
        "executing_command = f\"./{executable_name} < {input_file_name}\" if platform.system() != 'Windows' else f\"{executable_name} < {input_file_name}\"\n",
        "\n",
        "# Coverage command\n",
        "coverage_command = f\"gcov {executable_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1y5ACMhVqIT",
        "outputId": "20202009-1af3-4556-cab5-5f48a6ca42e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compilation successful\n",
            "--------------------------------------------------\n",
            "olleH\n",
            "\n",
            "--------------------------------------------------\n",
            "File 'reverse_string.cpp'\n",
            "Lines executed:93.75% of 16\n",
            "Creating 'reverse_string.cpp.gcov'\n",
            "\n",
            "File '/usr/include/c++/11/iostream'\n",
            "No executable lines\n",
            "Removing 'iostream.gcov'\n",
            "\n",
            "Lines executed:93.75% of 16\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    subprocess.run(compilation_command, shell=True, check=True)\n",
        "    print(\"Compilation successful\\n\" + '-'*50)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Compilation failed with error: {e}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(executing_command, shell=True, check=True, capture_output=True, text=True)\n",
        "    print(result.stdout + \"\\n\" + '-'*50)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Execution failed with error: {e}\")\n",
        "    print(\"Error Output:\", e.stderr)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(coverage_command, shell=True, check=True, capture_output=True, text=True)\n",
        "    print(result.stdout + '\\n')\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Coverage failed with error: {e}\")\n",
        "    print(\"Error Output:\", e.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CSXK-HiixTK",
        "outputId": "2e1fc60d-639e-4569-e196-6f1056a2d664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        -:    0:Source:reverse_string.cpp\n",
            "        -:    0:Graph:./reverse_string.gcno\n",
            "        -:    0:Data:./reverse_string.gcda\n",
            "        -:    0:Runs:1\n",
            "        -:    1:// Include the iostream header file\n",
            "        -:    2:#include <iostream>\n",
            "        -:    3:#include <cstring>\n",
            "        -:    4:using namespace std;\n",
            "        -:    5:\n",
            "        -:    6:// A function definition for a function that reverses a string\n",
            "        1:    7:char* reverse_string(char* str) {\n",
            "        -:    8:    // Get the length of the string\n",
            "        1:    9:    int len = strlen(str);\n",
            "        -:   10:    // Allocate memory for the reversed string\n",
            "        1:   11:    char* rev = (char*)malloc(len + 1);\n",
            "        -:   12:    // Check if the memory allocation was successful\n",
            "        1:   13:    if (rev == NULL) {\n",
            "    #####:   14:    return NULL;\n",
            "        -:   15:    }\n",
            "        -:   16:    // Copy the characters from the original string to the reversed string in reverse order\n",
            "        6:   17:    for (int i = 0; i < len; i++) {\n",
            "        5:   18:    rev[i] = str[len - i - 1];\n",
            "        -:   19:    }\n",
            "        -:   20:    // Add the null terminator to the reversed string\n",
            "        1:   21:    rev[len] = '\\0';\n",
            "        -:   22:    // Return the reversed string\n",
            "        1:   23:    return rev;\n",
            "        -:   24:}\n",
            "        -:   25:\n",
            "        1:   26:int main() {\n",
            "        1:   27:    const int maxInputLength = 100;  // Adjust the maximum input length as needed\n",
            "        -:   28:    char input[maxInputLength];\n",
            "        -:   29:\n",
            "        -:   30:    // Get input from the user\n",
            "        1:   31:    std::cin.getline(input, maxInputLength);\n",
            "        -:   32:\n",
            "        -:   33:    // Call the reverse_string function\n",
            "        1:   34:    char* reversed = reverse_string(input);\n",
            "        -:   35:\n",
            "        -:   36:    // Display the result\n",
            "        1:   37:    std::cout << reversed << std::endl;\n",
            "        -:   38:\n",
            "        -:   39:    // Free the allocated memory\n",
            "        1:   40:    free(reversed);\n",
            "        -:   41:\n",
            "        1:   42:    return 0;\n",
            "        -:   43:}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Specify the file path\n",
        "file_path = file_name + '.gcov'  # Replace with the actual path to your text file\n",
        "\n",
        "# Open the file in read mode ('r' for reading)\n",
        "with open(file_path, 'r') as file:  # Remove quotes around file_path\n",
        "    # Read the contents of the file\n",
        "    file_contents = file.read()\n",
        "\n",
        "# Display or process the file contents\n",
        "print(file_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV2Bg5D_i0Uv",
        "outputId": "5eaa5e08-7e70-42a7-881f-5c37eac6e5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Line 14: return NULL;\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Use regular expression to find lines after \"#####\"\n",
        "pattern = re.compile(r'#####:\\s+(\\d+):(.*?)\\n')\n",
        "matches = pattern.findall(file_contents)\n",
        "# Print the result\n",
        "# Print the result\n",
        "for match in matches:\n",
        "    line_number = match[0]\n",
        "    content = match[1].strip()\n",
        "    print(f\"Line {line_number}: {content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPRXdtGGVqIU",
        "outputId": "25662aea-c04a-4567-93ef-b39cc49895ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!g++ --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTtmwmklVqIV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
